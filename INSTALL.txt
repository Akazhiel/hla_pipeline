# Install Anaconda if you have not done it already

mkdir -p ~/shared
cd ~/shared

# Create environment with all the tools
conda env create -f environment.yml

# Install GSUTIL to download references
# You need to create .boto config with gsutil config and then disable integrity check by setting this line check_hashes = if_fast_else_skip
pip install gsutil

# Download mhcflurry models
mhcflurry-downloads fetch models_class1_presentation

# Install git-lfs (instructions for Centos)
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash
sudo yum install git-lfs

# Install arcasHLA (requires git-lfs)
git clone https://github.com/RabadanLab/arcasHLA.git
cd arcasHLA/
./arcasHLA reference --update

cd ~/shared
# Install HLA-LA (references must be downloaded and built)
wget http://www.well.ox.ac.uk/downloads/PRG_MHC_GRCh38_withIMGT.tar.gz
mkdir -p HLA-LA/graphs
tar -xvf PRG_MHC_GRCh38_withIMGT.tar.gz
mv PRG_MHC_GRCh38_withIMGT HLA-LA/graphs/
~/anaconda3/envs/hla/opt/hla-la/bin/HLA-LA --action prepareGraph --PRG_graph_dir HLA-LA/graphs/PRG_MHC_GRCh38_withIMGT
mkdir ~/anaconda3/envs/hla/opt/hla-la/graphs
mv ~/shared/HLA-LA/graphs/PRG_MHC_GRCh38_withIMGT ~/anaconda3/envs/hla/opt/hla-la/graphs/

cd ~/shared
# Install Strelka (Conda version is only compatible with Python 2.7)
wget https://github.com/Illumina/strelka/releases/download/v2.9.10/strelka-2.9.10.centos6_x86_64.tar.bz2
tar -xjf strelka-2.9.10.centos6_x86_64.tar.bz2
mv strelka-2.9.10.centos6_x86_64 ~/shared/strelka

# Install Annovar. Download link may be expired (email the developer for new link if expired)
cd ~/shared
wget http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz
tar -xvf annovar.latest.tar.gz

# Download GRCh38 references for Annovar
cd annovar
./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar knownGene humandb/
./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar ensGene humandb/
./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar refGene humandb/

# Download hg19 references for Annovar
./annotate_variation.pl -downdb -buildver hg19 -webfrom annovar knownGene humandb/
./annotate_variation.pl -downdb -buildver hg19 -webfrom annovar ensGene humandb/
./annotate_variation.pl -downdb -buildver hg19 -webfrom annovar refGene humandb/

# Install GATK3 from archives
cd ~/shared
gsutil cp gs://gatk-software/package-archive/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef.tar.bz2 .
tar xjf GenomeAnalysisTK-3.8-1-0-gf15c1c3ef.tar.bz2
mv GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar gatk3.8.jar

cd ~/shared
# Download references for GRCh38 and build STAR index
mkdir -p GRCh38
cd GRCh38
gsutil -m cp -r gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.dict .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf* .
gsutil -m cp -r gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz* .
gsutil -m cp -r gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz* .
wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/gencode.v34.primary_assembly.annotation.gtf.gz
gunzip gencode.v34.primary_assembly.annotation.gtf.gz
mkdir -p STARIndex
STAR --runMode genomeGenerate --runThreadN 20 --genomeDir STARIndex \
  --genomeFastaFiles Homo_sapiens_assembly38.fasta \
  --sjdbGTFfile gencode.v34.primary_assembly.annotation.gtf

cd ~/shared
# Download references for GRCh38 and build STAR index
mkdir -p hg19
cd hg19
gsutil -m cp -r gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.dict* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg19/v0/Mills_and_1000G_gold_standard.indels.b37.vcf.gz* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg19/v0/1000G_phase1.snps.high_confidence.b37.vcf.gz* .
gsutil -m cp -r gs://gcp-public-data--broad-references/hg19/v0/dbsnp_138.b37.vcf.gz* .
gsutil -m cp -r gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf* .
gsutil -m cp -r gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf* .
wget ftp://ftp.ensembl.org/pub/grch37/release-100/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz
gunzip Homo_sapiens.GRCh37.87.gtf.gz
mkdir -p STARIndex
STAR --runMode genomeGenerate --runThreadN 20 --genomeDir STARIndex \
  --genomeFastaFiles Homo_sapiens_assembly19.fasta \
  --sjdbGTFfile Homo_sapiens.GRCh37.87.gtf

# Create hg38 and hg19 dictionaries following the steps in the notebooks located in /dictionaries

cd ~
# Clone the pipeline and install it
git clone https://github.com/jfnavarro/hla_pipeline.git
cd hla_pipeline
cp shared/* ~/shared/
python setup.py install
